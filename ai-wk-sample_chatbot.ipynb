{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_W1ylr97brR"
      },
      "source": [
        "\n",
        "**Hello this is my first project --> if you have any comment please comment:)\n",
        "สวัสดีครับ นี่คือโปรเจคแรกของผม ------> ถ้าคุณมีคำถามก็คอมเม้นมาได้เลยครับ :)**\n",
        "\n",
        "สำหรับ โปรเจคแรกของผมคือ chatbot ที่ใช้สำหรับตอบคำถามของเราเอง หรือ personal assistance ของเราเองซึ่งก็อยากให้มันจำส่งที่เราบอกได้ และ สามารถ เทรน dataset ไปได้ โดยสำหรับ Prototype แรก ก็ใช้ dataset ของ hugging face มาก่อน"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNjuedEr9G1f"
      },
      "source": [
        "AutoTokenizer ใช้สำหรับแปลงข้อความเป็น token\n",
        "\n",
        "AutoModelForCausalLM โหลดโมเดลสำหรับงาน \"สร้างข้อความ\"\n",
        "\n",
        "device_map=\"auto\" ให้โมเดลจัดการกับ GPU เอง\n",
        "\n",
        "load_in_8bit=True ใช้ quantization เพื่อลดหน่วยความจำ (ผ่าน bitsandbytes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KjXUTr6T7UFl"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade pip\n",
        "!pip install transformers==4.36.2 peft==0.5.0 datasets\n",
        "\n",
        "import os\n",
        "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMbYzkda_VlL"
      },
      "outputs": [],
      "source": [
        "pip install huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tU6qGlt__VlL"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "snapshot_download(repo_id=\"microsoft/phi-2\", local_dir=\"./phi2\", local_dir_use_symlinks=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpNMvZn__Vhj"
      },
      "outputs": [],
      "source": [
        "### โมเดลที่เราจะใช้คือ microsoft/phi-2 — ขนาดเล็ก ฉลาด และใช้ทรัพยากรไม่เยอะ เหมาะกับ Chatbot ##\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "model_name = \"./phi2\"  # โหลดจาก local path\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "# ส่งโมเดลไปที่ GPU (ถ้ามี) หรือ CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6iYsw7m7bXG"
      },
      "outputs": [],
      "source": [
        "## import json สร้าง ข้อมูลมา ขำขำก่อน\n",
        "import json\n",
        "\n",
        "sample_data = [\n",
        "    {\"instruction\": \"แนะนำตัวเอง\", \"output\": \"สวัสดีครับ ผมคือบอทที่ถูกฝึกมาให้ตอบคำถามภาษาไทย!\"},\n",
        "    {\"instruction\": \"ภาษา Python คืออะไร\", \"output\": \"Python เป็นภาษาที่อ่านง่าย เหมาะกับผู้เริ่มต้น...\"},\n",
        "    {\"instruction\": \"วิธีชงกาแฟดำ\", \"output\": \"ต้มน้ำให้ร้อน เทน้ำผ่านกาแฟบดโดยใช้เครื่องดริปหรือกาแฟฟิลเตอร์\"}\n",
        "]\n",
        "\n",
        "with open(\"train_data.jsonl\", \"w\") as f:\n",
        "    for item in sample_data:\n",
        "        f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgwqU5qOCgge"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from datasets import Dataset\n",
        "\n",
        "# โหลดจากไฟล์ JSONL เป็น list\n",
        "with open(\"train_data.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_data = [json.loads(line) for line in f]\n",
        "\n",
        "# แปลงเป็น HuggingFace Dataset\n",
        "dataset = Dataset.from_list(raw_data)\n",
        "\n",
        "# ฟังก์ชันรวม prompt + response เป็นข้อความเดียว\n",
        "def format_prompt(example):\n",
        "    return f\"\"\"### คำถาม:\n",
        "{example['instruction']}\n",
        "\n",
        "### คำตอบ:\n",
        "{example['output']}\"\"\"\n",
        "\n",
        "# ถ้า tokenizer ไม่มี pad_token ให้เพิ่มเข้าไป\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.add_special_tokens({'pad_token': tokenizer.eos_token})\n",
        "    model.resize_token_embeddings(len(tokenizer))  # สำคัญ! ให้โมเดลรู้ว่ามี token เพิ่มเข้ามา\n",
        "\n",
        "# Tokenize ทุกตัวอย่าง\n",
        "def tokenize_function(example):\n",
        "    prompt = format_prompt(example)\n",
        "    return tokenizer(prompt, truncation=True, padding=\"max_length\", max_length=256)\n",
        "\n",
        "# แปลงข้อมูล\n",
        "tokenized_dataset = dataset.map(tokenize_function)\n",
        "\n",
        "# เตรียม data collator\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9d1wv2OHMi7l"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y peft transformers\n",
        "!pip install -U \"peft==0.9.0\"\n",
        "!pip install -U transformers==4.38.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsMyKddE_VlN"
      },
      "outputs": [],
      "source": [
        "## Check model layer ดูโมเดล layer ว่ามีอะไรบาง\n",
        "\n",
        "for name, module in model.named_modules():\n",
        "    if any(keyword in name.lower() for keyword in [\"linear\", \"mlp\", \"dense\", \"fc\"]):\n",
        "        print(name)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHqR-f9s_VlN"
      },
      "source": [
        "Layer ที่เราจะใช้ในการทำ LoRA\n",
        "\n",
        "\n",
        "self_attn.dense\n",
        "mlp.fc1\n",
        "mlp.fc2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcrtluHRFZxK"
      },
      "outputs": [],
      "source": [
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "\n",
        "## Config lora\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"self_attn.dense\", \"mlp.fc1\", \"mlp.fc2\"],  # ← ตรงกับของ phi-2\n",
        "    lora_dropout=0.05,\n",
        "    bias=\"none\",\n",
        "    task_type=TaskType.CAUSAL_LM\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq23WCuhGuj9"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade transformers\n",
        "import transformers\n",
        "print(transformers.__version__)\n",
        "\n",
        "!pip uninstall -y peft transformers\n",
        "!pip uninstall -y accelerate\n",
        "\n",
        "!pip install -U \"peft==0.9.0\"\n",
        "!pip install -U transformers==4.38.1\n",
        "!pip install -U accelerate==0.25.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF0dofSd_VlO"
      },
      "outputs": [],
      "source": [
        "import transformers, accelerate\n",
        "print(\"Transformers version:\", transformers.__version__)\n",
        "print(\"Accelerate version:\", accelerate.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCkFP7FuGcGH"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "## FOR PC ##\n",
        "\n",
        " training_args = TrainingArguments(\n",
        "     output_dir=\"./chatbot-lora-phi2\",\n",
        "     per_device_train_batch_size=2,\n",
        "     num_train_epochs=3,\n",
        "     logging_steps=5,\n",
        "     save_steps=20,\n",
        "     save_total_limit=2,\n",
        "     evaluation_strategy=\"no\",\n",
        "     fp16=True,  # ถ้าไม่มี GPU รองรับ FP16 ก็เปลี่ยนเป็น False ได้\n",
        "     report_to=\"none\"\n",
        " )\n",
        "\n",
        "\n",
        "## FOR MAC ##\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir=\"./chatbot-lora-phi2\",\n",
        "#     per_device_train_batch_size=1,\n",
        "#     num_train_epochs=3,\n",
        "#     logging_steps=5,\n",
        "#     save_steps=20,\n",
        "#     save_total_limit=2,\n",
        "#     evaluation_strategy=\"no\",\n",
        "#     report_to=\"none\"  # ปิดการ log ไปยังระบบภายนอก เช่น wandb\n",
        "# )\n",
        "\n",
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=tokenized_dataset,\n",
        "#     tokenizer=tokenizer,\n",
        "#     data_collator=data_collator,\n",
        "# )\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}